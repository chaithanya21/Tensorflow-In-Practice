{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL Assesment",
      "provenance": [],
      "authorship_tag": "ABX9TyNvEq8eJydZ5MimGJx0tFk+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaithanya21/Tensorflow-In-Practice/blob/master/DL_Assesment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS7582RCB3dT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzctH8skB9qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BllFOfUXCydx",
        "colab_type": "code",
        "outputId": "6fbe0a4d-d027-4874-fb79-f234fbfda662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0SNfm_JDKPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkUI2RroFdea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "from textblob.sentiments import NaiveBayesAnalyzer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iyAH08wjLHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textblob import TextBlob\n",
        "from textblob.taggers import NLTKTagger\n",
        "nltk_tagger = NLTKTagger()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly4SehUygzqG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2540dc21-b6a2-46de-8a32-06efac5b82db"
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "  "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE_qp2KaDWhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(Sentence,num_words=100,oov_token='OOV'):\n",
        "  \n",
        "  tokenizer=Tokenizer(num_words=num_words,oov_token=oov_token)\n",
        "  tokenizer.fit_on_texts(Sentence)\n",
        "  word_index=tokenizer.word_index\n",
        "  print('\\nword_index_of_Sentence:\\n',word_index)\n",
        "  Sequences=tokenizer.texts_to_sequences(Sentence)\n",
        "  print('Sentences Encoded as the Sequence of Tokens:',Sequences)\n",
        "  padded_seq=pad_sequences(Sequences,padding='post')\n",
        "  print('\\nThe Padded Sequence:\\n',padded_seq)\n",
        "  df = pd.DataFrame(columns = ['Line','Polarity', 'Subjectivity' ,'Sentiment','Classification'])\n",
        "  blob=TextBlob(\".\\n\".join(Sentence),analyzer=NaiveBayesAnalyzer(),pos_tagger=nltk_tagger)\n",
        "  tags=blob.pos_tags\n",
        "  DICT={}\n",
        "  for a,b in tags:\n",
        "    DICT.setdefault(a, []).append(b)\n",
        "  print('Parts of Speech:',DICT)\n",
        "  POS_dataframe=pd.DataFrame(tags,columns=['word','pos'])\n",
        "  print(POS_dataframe.head(10))\n",
        "  for sentence in blob.sentences:\n",
        "    df.loc[len(df)] = [str(sentence),sentence.polarity, sentence.subjectivity,sentence.sentiment,sentence.sentiment.classification]\n",
        "  return df\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        " \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf0HZvjIEj4k",
        "colab_type": "code",
        "outputId": "cd62bbd2-5828-406b-ccd6-b259f4658957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "tokenizer(Sentence=['This is very bad','This is Very Good'],num_words=100,oov_token='<OOV>')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "word_index_of_Sentence:\n",
            " {'<OOV>': 1, 'this': 2, 'is': 3, 'very': 4, 'bad': 5, 'good': 6}\n",
            "Sentences Encoded as the Sequence of Tokens: [[2, 3, 4, 5], [2, 3, 4, 6]]\n",
            "\n",
            "The Padded Sequence:\n",
            " [[2 3 4 5]\n",
            " [2 3 4 6]]\n",
            "Parts of Speech: {'This': ['DT', 'DT'], 'is': ['VBZ', 'VBZ'], 'very': ['RB'], 'bad': ['JJ'], 'Very': ['RB'], 'Good': ['JJ']}\n",
            "   word  pos\n",
            "0  This   DT\n",
            "1    is  VBZ\n",
            "2  very   RB\n",
            "3   bad   JJ\n",
            "4  This   DT\n",
            "5    is  VBZ\n",
            "6  Very   RB\n",
            "7  Good   JJ\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Line</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is very bad.</td>\n",
              "      <td>-0.91</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>(neg, 0.37758749684360443, 0.6224125031563954)</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is Very Good</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>(pos, 0.5502163032864825, 0.4497836967135176)</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Line  ...  Classification\n",
              "0  This is very bad.  ...             neg\n",
              "1  This is Very Good  ...             pos\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7xzI4s9wTRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "0c596b2e-5d28-4bd9-cccc-8f2bfecd53d4"
      },
      "source": [
        "tokenizer(['Steve smith is the greatest test batsman of Modern test  Cricket','Virat is the best the ODI cricketer of the decade'])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "word_index_of_Sentence:\n",
            " {'OOV': 1, 'the': 2, 'is': 3, 'test': 4, 'of': 5, 'steve': 6, 'smith': 7, 'greatest': 8, 'batsman': 9, 'modern': 10, 'cricket': 11, 'virat': 12, 'best': 13, 'odi': 14, 'cricketer': 15, 'decade': 16}\n",
            "Sentences Encoded as the Sequence of Tokens: [[6, 7, 3, 2, 8, 4, 9, 5, 10, 4, 11], [12, 3, 2, 13, 2, 14, 15, 5, 2, 16]]\n",
            "\n",
            "The Padded Sequence:\n",
            " [[ 6  7  3  2  8  4  9  5 10  4 11]\n",
            " [12  3  2 13  2 14 15  5  2 16  0]]\n",
            "Parts of Speech: {'Steve': ['NNP'], 'smith': ['NN'], 'is': ['VBZ', 'VBZ'], 'the': ['DT', 'DT', 'DT', 'DT'], 'greatest': ['JJS'], 'test': ['NN', 'NN'], 'batsman': ['NN'], 'of': ['IN', 'IN'], 'Modern': ['NNP'], 'Cricket': ['NN'], 'Virat': ['NNP'], 'best': ['JJS'], 'ODI': ['NNP'], 'cricketer': ['NN'], 'decade': ['NN']}\n",
            "       word  pos\n",
            "0     Steve  NNP\n",
            "1     smith   NN\n",
            "2        is  VBZ\n",
            "3       the   DT\n",
            "4  greatest  JJS\n",
            "5      test   NN\n",
            "6   batsman   NN\n",
            "7        of   IN\n",
            "8    Modern  NNP\n",
            "9      test   NN\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Line</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Steve smith is the greatest test batsman of Mo...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.65</td>\n",
              "      <td>(pos, 0.9698894478665078, 0.030110552133492036)</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Virat is the best the ODI cricketer of the decade</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>(pos, 0.6665713245087733, 0.3334286754912267)</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Line  ...  Classification\n",
              "0  Steve smith is the greatest test batsman of Mo...  ...             pos\n",
              "1  Virat is the best the ODI cricketer of the decade  ...             pos\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1ye8KvNxNOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}